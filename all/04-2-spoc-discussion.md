#lec9: 虚存置换算法spoc练习

## 视频相关思考题

### 9.1 页面置换算法的概念

1. 设计置换算法时需要考虑哪些影响因素？如何评判的好坏？

2. 全局和局部置换算法的不同？

### 9.2 最优算法、先进先出算法和最近最久未使用算法

1. 最优算法、先进先出算法和LRU算法的思路？

### 9.3 时钟置换算法和最不常用算法

1. 时钟置换算法的思路？

2. 改进的时钟置换算法与时钟置换算法有什么不同？

3. LFU算法的思路？


### 9.4 Belady现象和局部置换算法比较

1. 什么是Belady现象？如何判断一种置换算法是否存在Belady现象？

2. 请证明LRU算法不存在Belady现象。

### 9.5 工作集置换算法

1. CPU利用率与并发进程数的关系是什么？

2. 什么是工作集？

3. 什么是常驻集？

4. 工作集算法的思路？

### 9.6 缺页率置换算法

1. 缺页率算法的思路？

### 9.7 抖动和负载控制

1. 什么是虚拟内存管理的抖动现象？

2. 操作系统负载控制的最佳状态是什么状态？

3. 局部置换算法（如FIFO, LRU等）是否能作为全局置换算法来使用？为什么？

----

## 扩展思考题

1.  改进时钟置换算法的极端情况: 如果所有的页面都被修改过了，这时需要分配新的页面时，算法的performance会如何？能否改进在保证正确的前提下提高缺页中断的处理时间？

2.  如何设计改进时钟算法的写回策略?

3. （spoc）根据你的`学号 mod 4`的结果值，确定选择四种页面置换算法（0：LRU置换算法，1:改进的clock 页置换算法，2：工作集页置换算法，3：缺页率置换算法）中的一种来设计一个应用程序（可基于python, ruby, C, C++，LISP等）模拟实现，并给出测试用例和测试结果。请参考如python代码或独自实现。
 - [页置换算法实现的参考实例](https://github.com/chyyuu/ucore_lab/blob/master/related_info/lab3/page-replacement-policy.py)     

4. 请判断OPT、LRU、FIFO、Clock和LFU等各页面置换算法是否存在Belady现象？如果存在，给出实例；如果不存在，给出证明。

5. 了解LIRS页置换算法的设计思路，尝试用高级语言实现其基本思路。此算法是江松博士（导师：张晓东博士）设计完成的，非常不错！
	- 参考信息：
 	- [LIRS conf paper](http://www.ece.eng.wayne.edu/~sjiang/pubs/papers/jiang02_LIRS.pdf)
	 - [LIRS journal paper](http://www.ece.eng.wayne.edu/~sjiang/pubs/papers/jiang05_LIRS.pdf)
	 - [LIRS-replacement ppt1](http://dragonstar.ict.ac.cn/course_09/XD_Zhang/(6)-LIRS-replacement.pdf)
	 - [LIRS-replacement ppt2](http://www.ece.eng.wayne.edu/~sjiang/Projects/LIRS/sig02.ppt)

## 问答题

1. [基础] 全局和局部置换算法有何不同？分别有哪些算法？

2. [基础] 简单描述OPT、FIFO、LRU、Clock、LFU的工作过程和特点
  
3. [进阶，开放，推荐]考虑置换算法的收益和开销，综合评判在何种情境下使用何种算法比较合适呢？

4. [基础] Clock和LFU算法存在那些问题，如何改进？
   
5. [进阶-，开放] Clock算法仅仅能够记录近期是否访问过这一信息，对于访问的频度几乎没有记录，如何改进这一点？(这里针对恢复计数的LFU算法也可以提出类似问题)

6. [基础] LRU算法的缺页率是否总是优于FIFO算法呢？为何？

7. [基础] 描述belady现象。[进阶] 哪些算法有belady现象？[困难]思考belady现象的成因，尝试给出说明OPT和LRU等没有belady现象的思路（仅仅是思路，大体有一个方向即可）。

8. [进阶] 使用自映射有何优势？有何代价？

9. [进阶] 考虑在 32 位 x86 下使用页表自映射。为了方便用三元组 (a, b, c) 表示虚拟/物理地址 ((a<<22)  +(b<<12) + c)，其中 0<=a,b<1024，0<=c<4096。假设页目录的物理地址是 (A, B, 0)，并且页目录的第 e 项  (0<=e<1024) 是自映射项，就是说在 (A, B, 4*e) 页目录项指向页目录自己的物理地址 (A, B, 0).

  	9.1 页目录的第 i 项的物理地址是多少？通过自映射访问的虚拟地址是多少？

    9.2 用一句赋值语句，取消虚拟地址 (x,y,0) 所在页的地址映射。那重新映射到物理地址 (C,D,0)呢（用 flags 表示页表项的诸标志位）？
    
    9.3 页表项指向的页的物理地址可以直接从页表项的内容读出。但采用自映射后，为什么把页表项的地址（最后两位清零）左移10位，就得到了页表项指向的页的虚拟地址了？

1. [基础]并发进程数和CPU利用率有何关系？为什么会是这样？

    关系：当进程数较少时，随着进程数的增加，CPU利用率提高，当进程数到达一定数量后，CPU利用率不再提高，且如果进程数继续增加，CPU利用率迅速下降。

    原因：

    * 程序的操作一般分为CPU密集型操作和IO密集型操作，且这两种操作交替进行。

    * 当进程数量较少时，如果所有的进程都进入IO阶段，CPU就只能等待，利用率较低。

    * 当进程数量足够多，能够使得CPU不存在等待状态时，CPU利用率基本保持不变。

    * 当进程数过多时，各个进程的工作集数量过多，导致出现了大量缺页，CPU忙于处理缺页，导致CP降低。

1. [进阶-，开放] 如何理解计算机整体处于均衡的繁忙状态？请从负载均衡和各个存储层次两个方面考虑。

    负载均衡：指CPU密集的操作和IO密集的操作基本均衡，一方面，CPU不会等待IO而空闲，另一方面，IO不会等待CPU的缺页处理等而阻塞。

    各层次存储之间的均衡：指通过选取合适的替换算法，使得越"热"的数据位于层次存储的越上级，使得访问越下层存储的概率快速下降（也就是各层的miss率都比较小）。达成越底层访问次数越少（指数递减），但是读取量越大（也应该是指数递增）的情况。

1. [基础]什么是工作集？什么是常驻集？简单描述工作集算法的工作过程。

    工作集：（一段时间内）进程的属性。指某进程在过去一段时间内访问的所有页面构成的集合。

    常驻集：与置换算法相关。指当前驻留内存的页面集合。

    工作过程：目标是使得常驻集尽可能接近工作集。做法是淘汰前若干次访存没有访问的页面。具体过程如下：

    * 维护一个数量固定访存队列（访存窗口）

    * 访存时，如果常驻集中的页面在访存窗口中没有访问，将其换出常驻集

    * 缺页时，将新页直接加入常驻集

1. [基础]简单描述缺页率算法的思路。

    基本思路：通过控制缺页率来控制常驻集的大小。

    做法：规定一个期望的缺页率和时间窗口。从过两次缺页的时间间隔来估计缺页率。如果缺页率过高，则缺页时直接将新页面加入常驻集。如果过低，则将时间窗口内没有访问的页面换出常驻集。

1. [基础]什么是抖动？如何减少抖动的出现？

    概念：指进程数量过多而各个内存常驻集不足，从而内存常驻页面频繁在各个进程工作集之间切换，进而导致大量缺页的现象。

    方法：进行负载控制，选择合适的进程数量。

1. [进阶-]局部置换算法和全局置换算法有何主要区别？局部置换算法是否能作为全局置换算法来使用效果如何？为什么？

    区别：局部置换算法页面数量固定，会尽可能利用全部页面。全局算法针对每个进程页面内数量不固定，会主动去除不常用的页面。

    效果：效果不好。局部算法不会针对不同进程的特征做出自适应调整。如果不做改动，每一个进程都会近乎耗尽整个物理内存，从而导致严重进程切换后的大量缺页，而事先估计一个进程工作集的大小是困难的。

1. [基础]什么是缓存污染？它和内存抖动有何异同？


    缓存污染概念：将不常用的数据放入缓存，挤出常用数据，从而导致缓存利用率降低的现象。
    
    相同：都存在由于新数据写入而使得原有常用数据被换出的现象。
    
    不同：成因和解决办法不相似，内存抖动无法通过有效的置换策略避免，应该进行负载控制。而缓存污染是由于换出页面选择不合理导致的。

1. [基础]面向缓存的置换算法是为了解决什么问题？解决的基本思路为何？

    传统的页面置换算法如LRU在IObuffer的情境下不能够适应常见的访问模式，会出现缓存污染的现象。这些访问模式包括：顺序访问、循环访问、时间密集访问、概率访问。

    视频中提到的算法主要是对LRU进行了改进，通过利用访问频度的信息，更加合理的区分页面的热度，使得换出真正不常用的页面。

1. [基础]简述FBR的思路和做法？（针对LRU-K也可以出类似题目）

    思路：LRU + LFU，在小尺度内使用LRU，避免密集访问导致的LFU计数暴增。大尺度上使用LFU，利用频度信息。

    做法：把LRU栈分为三段：新区域、中间区域、旧区域。增加引用计数，新区域被访问计数不增加，淘汰是淘汰旧区域引用计数最少的。

1. [基础]2Q算法针对LRU-K做了那些修改？

    K = 2

    LRU-K的访问历史队列只保存Buffer Cache的元数据信息；2Q的访问历史队列不仅仅是保存元数据（如访问时间等），也保存Buffer Cache本身了，所以，它与缓冲区都存放了BUFFER，使用FIFO策略；

    LRU-K的缓冲区采用优先级队列策略，而2Q的缓冲区简化为LRU队列策略


1. 补充：LRU-K等的特点和算法

	我除了看论文，也参考了 http://www.itgo.me/a/x2374856251384962283/Database- 我觉得对LRU-K, 2Q, LIRS的理解还还不错

	https://cloud.tencent.com/developer/article/1005742  对LIRS描述比较细

	特点：

	K指的是最后第K次访问的距离，也就是倒数第K次访问时和最近一次访问的时间差。LRU-K算法主要是对比最后第K次的访问距离，访问距离越大则代表每次的访问间隔越长，因此更容易被替换出cache。

	算法简要描述：

	1. 数据第一次被访问，加入到访问历史列表；
	2. 如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰；
	3. 当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到缓存队列中，并缓存此数据，缓存队列重新按照时间排序；
	4. 缓存数据队列中被再次访问后，重新排序；
	5. 需要淘汰数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。